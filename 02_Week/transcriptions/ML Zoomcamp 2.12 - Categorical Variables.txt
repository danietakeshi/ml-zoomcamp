[0:00:00.24 --> 0:00:07.08]	  Hi everyone, welcome back. This is lesson 12 of machine learning zoom camp session 2 and we will talk about categorical variables.
[0:00:07.56 --> 0:00:14.14]	  So categorical variables are variables that are categories. So these are typically strings. So these are not numbers.
[0:00:14.52 --> 0:00:22.58]	  So things like make, model, engine view type, transmission type, driven wheels, they are categorical variables.
[0:00:22.58 --> 0:00:30.92]	  So typically there are strings and we have quite a few of them. Here if we look at d-types, we have make, model and so on.
[0:00:30.96 --> 0:00:38.16]	  So all these things that have type objects, they are categorical variables.
[0:00:38.90 --> 0:00:49.32]	  But there is one variable that looks like it's numerical, number of doors, but it's actually not a numerical variable.
[0:0 --> 0:00:58.50]	  Because there are distinct types of cars. So there are cars that have two doors cars that have three doors and cars that have four doors.
[0:00:58.76 --> 0:01:11.02]	  Right. So these cars are quite different. So it's, it's not really a numerical number, numerical variable, even though it looks numerical, it just happened that the values of this variable are numbers.
[0:01:11.06 --> 0:01:15.14]	  That's why pandas treats them as usual numbers.
[0:01:16.06 --> 0:01:24.34]	  Right. And we want to use variables like that for our models, for our model, because they could be important.
[0:01:24.56 --> 0:01:32.04]	  So for example, for cars with two doors, they're probably more expensive than let's say car with four doors.
[0:01:32.14 --> 0:01:43.90]	  And the typical way of encoding such categorical variables is we represent, let's say we have here we have our column with different values.
[0:01:44.14 --> 0:01:52.52]	  So it can be like number of doors, right. It can be say two, three, four, again two.
[0:01:53.08 --> 0:01:57.86]	  And the way we usually encode it is we represent it with a bunch of binary columns.
[0:01:57.86 --> 0:02:06.78]	  So for each value, so let's say this is a number of doors to number of doors three and number of doors for
[0:02:06.78 --> 0:02:19.86]	  for each value, we have a different column. And then we put one like for this row, because the number of rows is two, then we, the number of doors is two.
[0:02:19.86 --> 0:02:24.64]	  That's why we put one in this column and put zeros everywhere.
[0:02:25.94 --> 0:02:31.30]	  And for this one, one goes here and this ones get zero.
[0:02:32.08 --> 0:02:40.62]	  And then for four, again, one goes here to the column number of doors four. And then here again we have two.
[0:02:41.46 --> 0:02:54.58]	  That's why we have one in the first column. So we represent one categorical column with multiple binary columns, multiple binary variables.
[0:02:55.04 --> 0:02:58.62]	  And the way we can do this in pandas is using this equals equals separator.
[0:02:58.90 --> 0:03:08.44]	  So let's say when we say that number of doors two equals to two, then basically it shows that for the first car, it's true.
[0:03:09.42 --> 0:03:15.76]	  So the number of doors is actually considered it's two. And then this is also two.
[0:03:16.60 --> 0:03:25.60]	  We can see it's true. So one thing we need to do now is just turn to it into integer. So we have here ones and zeros.
[0:03:26.16 --> 0:03:33.20]	  And for that, we can just use this as type function that turns a Boolean into integer.
[0:03:33.96 --> 0:03:39.92]	  And then we can do this for all of them, for two, three and four.
[0:03:41.60 --> 0:03:47.18]	  And so what we need to do now is just write it back to data frame.
[0:03:47.80 --> 0:04:00.58]	  And then the way we do this, we can just let's say have number of doors equals four and then have a capable variable like that.
[0:04:00.58 --> 0:04:10.48]	  And then it will create a new variable here, a new column in the data frame that is one for all the cars that have four doors.
[0:04:10.84 --> 0:04:18.36]	  And then we can do this for three, for two doors and for three doors.
[0:04:19.84 --> 0:04:23.82]	  So here it will be two, three.
[0:04:24.18 --> 0:04:34.64]	  But we don't of course need to do that. We can just write a loop that will look like for value in two, three, four.
[0:04:35.08 --> 0:04:36.32]	  So these are different values.
[0:04:37.44 --> 0:04:43.80]	  And then we can use here this string template.
[0:04:44.12 --> 0:04:50.94]	  So this, let's say number doors s and s will be replaced by something will pass.
[0:04:51.18 --> 0:04:53.72]	  So here in this case, it will be replaced by three.
[0:04:54.50 --> 0:04:56.54]	  In this case, it will be replaced by four.
[0:04:57.52 --> 0:05:01.38]	  So we will create a column for each of the values.
[0:05:02.24 --> 0:05:12.74]	  And here we just, we'll basically go through all the values of number of doors, two, three, four, and then create a separate column for that.
[0:05:13.48 --> 0:05:17.06]	  But I will not execute this now here because I will add this.
[0:05:17.06 --> 0:05:18.76]	  Oh, actually I can execute this.
[0:05:19.48 --> 0:05:21.84]	  Let's see what happens.
[0:05:23.32 --> 0:05:29.18]	  So, okay, I forgot to add this here.
[0:05:29.58 --> 0:05:33.56]	  So it needs to replace s with v.
[0:05:34.82 --> 0:05:38.34]	  We see it appeared here.
[0:05:38.46 --> 0:05:41.14]	  Of course, I need to delete this now.
[0:05:46.42 --> 0:05:54.18]	  Yeah, and also delete this three and four.
[0:05:54.88 --> 0:0]	  So now they should be gone.
[0:05:57.10 --> 0:06:04.28]	  This is how we can represent categorical variables and also put them in our feature matrices.
[0:06:04.54 --> 0:06:07.42]	  So let's modify our prepare x function.
[0:06:08.82 --> 0:06:15.76]	  Again, we make a copy because we don't want to accidentally write these columns in our, in our data frames.
[0:06:16.64 --> 0:06:25.46]	  So here we will go through three values, these three values, and basically do the same thing.
[0:06:27.30 --> 0:06:30.92]	  So, and then I'll just replace the f train with the f.
[0:06:33.04 --> 0:06:49.38]	  So, and here we also need to add this name, the feature name to the list of features, because later we want to, we want to get these features from the data frame, and then put them to the matrix x.
[0:06:50.06 --> 0:06:52.72]	  So that I will use the event function.
[0:06:54.44 --> 0:07:05.60]	  Here. So here I don't use a pant, because I want to create a new, a new list. So I don't want to change the base list every time.
[0:07:06.08 --> 0:07:18.66]	  Because otherwise, if I let's say use a pant here, then it will append the h value every time to this base list.
[0:07:18.66 --> 0:07:22.26]	  So in this case, I will actually need to do a copy.
[0:07:25.16 --> 0:07:27.98]	  So that's called features.
[0:07:29.52 --> 0:07:32.20]	  Then I append to the list.
[0:07:33.98 --> 0:07:39.48]	  So this is basically the same idea here. So we don't want to modify the list base.
[0:07:41.88 --> 0:07:51.88]	  Okay. So now, so we still compute the h variable, then we go through the values of number of doors, and then we put this to the features list.
[0:07:52.06 --> 0:07:56.80]	  So the features list will contain all the features we have from the baseline features.
[0:07:57.10 --> 0:08:04.84]	  Then we will have the age feature, and we will have three new features that is number of doors to number of doors, three and number of doors for.
[0:08:05.58 --> 0:0]	  So let's test if it works actually.
[0:08:10.50 --> 0:08:18.54]	  Prepare X. Let's test it on our, yeah, we see now that it adds a new set of columns.
[0:08:18.84 --> 0:08:26.22]	  One for those like this is number of doors to number of doors, three, number of doors for, and let's just copy this thing for training.
[0:08:26.64 --> 0:08:33.20]	  So we don't need to actually to change anything here and see if there is any improvement.
[0:08:34.38 --> 0:08:42.52]	  We see that the results. So the previous result was this one, let me just copy it.
[0:08:43.68 --> 0:08:48.22]	  So it improved only slightly like only a little bit.
[0:08:48.50 --> 0:08:54.68]	  The improvement is almost negligible. So the number of doors feature is not that useful.
[0:08:55.16 --> 0:09:00.76]	  But I'm pretty sure that if we add make the make should be quite useful.
[0:09:01.54 --> 0:09:09.96]	  So for that, if we look at make, we have quite a lot of values. Let's look at the unique.
[0:09:10.64 --> 0:09:17.76]	  So we have a lot of values and we can just what we can do is just look at the top, the most popular values.
[0:09:18.04 --> 0:09:21.70]	  So for that, we have this function called value counts.
[0:09:22.12 --> 0:09:37.64]	  And when we can see what are the most popular ones, I don't see that for top five, just this head function, we can see that for make these five are the most popular ones.
[0:09:38.36 --> 0:09:50.08]	  And again, so this is the values, this is the index. So if we want to get the actual values, we use this index index property and also rapid in usual.
[0:09:50.76 --> 0:09:58.24]	  I think this. So these are the most popular makes of cars, and we can include them in the same way as as number of doors.
[0:09:59.02 --> 0:10:01.82]	  So let's for now we can just copy and paste.
[0:10:06.54 --> 0:10:09.78]	  We just tried car makes.
[0:10:11.56 --> 0:10:12.62]	  Maybe just makes.
[0:10:13.34 --> 0:10:17.62]	  So we have makes here, then for V in makes.
[0:10:18.40 --> 0:10:25.70]	  So I'll just replace here this thing with make and this thing with make and this thing with make.
[0:10:25.76 --> 0:10:30.52]	  So the code is the same. So we're again for each of those makes.
[0:10:31.38 --> 0:10:49.58]	  And we have to have Chevrolet Ford Volkswagen Toyota dodge. So for each of them, we do a similar thing like here. So we actually will have five new columns here because there are five values, and then it will be for all the Chevrolet, it will be one.
[0:10:49.58 --> 0:10:54.72]	  Okay, so let's try to see if anything changes.
[0:10:55.28 --> 0:11:00.30]	  So just copy this and run it.
[0:11:01.10 --> 0:11:03.62]	  And we can see that the results improved.
[0:11:04.06 --> 0:11:13.76]	  But of course, the improvement is not as drastic as when we added edge, but still like it increased decreased 1%, which is quite okay.
[0:11:13.76 --> 0:11:19.32]	  We can do the same for other variables for other categories.
[0:11:19.86 --> 0:11:26.76]	  So let's say we have makes here, but in addition to makes we have, so let's look at again D types.
[0:11:27.76 --> 0:11:33.12]	  So we have engine fuel type that's a categorical variable.
[0:11:33.84 --> 0:11:35.80]	  Then we have transmission type.
[0:11:35.80 --> 0:11:41.50]	  That's categorical variable. Then we have driving driven wheel.
[0:11:41.98 --> 0:11:43.32]	  That's categorical variable.
[0:11:44.58 --> 0:11:53.10]	  Then vehicles market category, vehicle size, vehicle style. So all these are categories.
[0:11:54.08 --> 0:11:57.36]	  So now we have all the categorical variables.
[0:12:01.16 --> 0:12:10.06]	  I'm not adding a model here because there are simply too many models, but I'll add make and all these other ones.
[0:12:10.62 --> 0:12:12.18]	  So we'll have quite a few of them.
[0:12:13.02 --> 0:12:20.36]	  So what we can do now is we can do the same thing like we did here, but for all of this.
[0:12:21.20 --> 0:12:29.96]	  So we can do this for make, for engine fuel type, for transmission type, for driven wheels, for market category, for vehicle size, for vehicle style.
[0:12:30.50 --> 0:1]	  So what we can do is we can maybe create a first dictionary.
[0:12:35.92 --> 0:12:37.40]	  Let's call it categories.
[0:12:38.56 --> 0:12:45.06]	  And this dictionary will contain for each of the categories, we could contain the top five most common ones.
[0:12:45.60 --> 0:12:49.50]	  So now we will need to go over this list of categories.
[0:12:51.14 --> 0:12:57.80]	  And then for this, for each category, we'll get a list of the most common ones.
[0:12:59.30 --> 0:13:02.64]	  Okay, here we just need to replace this make with C.
[0:13:03.44 --> 0:13:05.96]	  And let's see what we get.
[0:13:07.22 --> 0:13:09.74]	  We need to give it a different name.
[0:13:11.16 --> 0:13:14.42]	  We can call it categorical variables.
[0:13:16.86 --> 0:13:24.72]	  Yeah, so now it should, yes, now for make it contains the most popular makes for engine fuel type, for transmission type.
[0:13:25.02 --> 0:1]	  So basically for all these variables, we know what the most popular values they have.
[0:13:33.68 --> 0:13:42.26]	  Now we can just take this prepare X function and just throw in all the, all the categories for that.
[0:13:42.82 --> 0:13:45.96]	  We'll need to make two loops.
[0:13:46.44 --> 0:13:59.54]	  So one is across for each item in this, so for each key of this dictionary, and then for each value inside, we will create a new, a new call.
[0:14:00.44 --> 0:14:04.82]	  So for, let's do for C in categories.
[0:14:07.84 --> 0:14:15.94]	  Then for, and actually we need to do this over key value pairs of the dictionary.
[0:14:16.24 --> 0:14:18.52]	  So we use items here.
[0:14:20.08 --> 0:14:26.32]	  Then we do another loop over the values of each category.
[0:14:26.88 --> 0:1]	  And then here we need to have something like that.
[0:14:31.24 --> 0:14:40.42]	  So it will replace the first one, the first percent as with C, and then the second percent as with heavy, right.
[0:14:40.52 --> 0:14:43.76]	  And here we need to do that.
[0:14:44.06 --> 0:14:46.72]	  And the last one is just a name.
[0:14:48.98 --> 0:14:52.52]	  So number of doors, I'll just keep like that.
[0:14:52.80 --> 0:14:53.62]	  And let's execute.
[0:14:54.58 --> 0:14:57.96]	  Now we again do the same thing.
[0:14:58.94 --> 0:15:03.90]	  We execute it and let's see what happens.
[0:15:04.90 --> 0:15:11.10]	  And what happens is now actually this value is significantly higher than what we had before.
[0:15:11.64 --> 0:15:15.10]	  So before we had 0.5, right.
[0:15:15.56 --> 0:15:18.04]	  And now all of a sudden it's 41.
[0:15:18.62 --> 0:15:19.72]	  Something went wrong.
[0:15:19.94 --> 0:15:30.46]	  And if we look at the values that we have, so you see the values that are linear regression function train linear regression function outputs, they're huge.
[0:15:30.76 --> 0:15:36.92]	  So this is, this is because scientific notation, it's very difficult to read what if you convert it to a integer.
[0:15:37.48 --> 0:15:40.08]	  So it's a huge, huge negative number.
[0:15:42.02 --> 0:15:46.36]	  And these weights, we see that some of them are also very large.
[0:15:46.52 --> 0:15:53.14]	  So for example, this, this row here, so this is, so this is a huge, huge, huge value.
[0:15:54.12 --> 0:15:54.94]	  So something went wrong.
[0:15:55.44 --> 0:15:59.66]	  We wanted to improve our model by adding more variables, but we just made it worse.
[0:15:59.88 --> 0:16:04.60]	  And in the next lesson, we will see why that happened and how to fix it.
