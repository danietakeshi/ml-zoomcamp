[0:00:00.44 --> 0:00:04.34]	  Welcome back. This is lesson three of machine learning Zoom
[0:00:04.34 --> 0:00:08.96]	  Come session two. And we stopped in the previous lesson on
[0:00:08.96 --> 0:0]	  looking at the columns of our data frame. So we wanted to
[0:0 --> 0:00:18.46]	  understand what columns are there and what they actually mean.
[0:00:18.86 --> 0:00:23.26]	  And this is what we'll do now. We'll do exploratory data analysis.
[0:00:23.82 --> 0:00:27.28]	  We want to understand how the data looks like
[0:00:27.30 --> 0:00:30.30]	  just to get a feeling what kind of values are there.
[0:00:30.72 --> 0:00:37.60]	  And just to learn more about the data and about the problem.
[0:00:38.50 --> 0:00:40.48]	  So we already know that some of these
[0:00:40.48 --> 0:00:50.60]	  some of these columns are strings. We also know that some of them are numbers.
[0:00:52.24 --> 0:00:55.94]	  And yeah, so we have basically strings and numbers.
[0:00:56.60 --> 0:0]	  So let's try to see what we actually have there.
[0:01:02.62 --> 0:01:08.08]	  So for that, so this is our data frame. So what we can do is we can
[0:01:08.08 --> 0:01:15.98]	  take a look at each column here and try to understand what kind of data
[0:01:16.80 --> 0:01:22.28]	  we have there. So we have these columns, right, which gives us the list of columns.
[0:01:22.70 --> 0:01:25.18]	  What we can do is we can just iterate over them.
[0:01:27.60 --> 0:01:35.68]	  And for each of these columns, print some statistics and maybe print some values and see
[0:01:35.68 --> 0:01:42.02]	  what kind of data is there. So let's do this. So first we can print the column name,
[0:01:42.18 --> 0:01:48.66]	  like column name and maybe some values. So print tf, call.
[0:01:50.86 --> 0:01:59.60]	  Good. So it tells us, okay, we have this. So let me just add one extra
[0:01:59.60 --> 0:02:06.96]	  lane rate here. So we have model make. And this is how the first five values look like.
[0:02:07.60 --> 0:02:15.02]	  So then basically this is the manufacturer of a car, model, year. So this is maybe not very
[0:02:15.02 --> 0:02:20.46]	  informative because these are the first values. So maybe what is more interesting for us is to
[0:02:20.46 --> 0:02:27.58]	  look at unique values because here we get that it's all b and w. It's interesting to know what
[0:02:27.58 --> 0:02:35.22]	  the other values that we have there. So what we can do is let's say call this method unique
[0:02:35.22 --> 0:02:45.22]	  and it returns unique values in the series. So bmw will be only once. We don't want to see all
[0:02:45.22 --> 0:02:54.48]	  unique values. Let's just take a look at first five. And perhaps what will also be interesting
[0:02:54.48 --> 0:03:02.28]	  is to know how many unique values are there. And for that, we use this n unique, which basically
[0:03:09.38 --> 0:03:17.30]	  tells us how many unique values are there. So for example, for the first one we have is manufacturer.
[0:03:18.10 --> 0:03:23.98]	  And so these are the first unique values that we have bmw, Audi, Fiat, Mercedes-Benz, Chrysler,
[0:03:24.22 --> 0:03:31.28]	  and there are 48 different values. So for model, of course, model is more granular. So there are
[0:03:31.28 --> 0:03:36.88]	  more different models because for each manufacturer, they have multiple models. So that's why we have
[0:03:36.88 --> 0:03:45.32]	  a lot more values. So here is a numerical variable. So this is numerical column. It has
[0:03:45.32 --> 0:03:54.14]	  different years, 28 of them. So this is the type of engine. So few that it gets like,
[0:03:54.30 --> 0:04:00.36]	  I'm not a car expert. Well, no, there is diesel and there's others, I guess. So there are 10
[0:04:00.36 --> 0:04:07.82]	  different types. Then this one is engine horsepower. How powerful the engine is, how many cylinders are
[0:04:07.82 --> 0:04:14.80]	  there, transmission type, driven wheels and all these kind of things we potentially can
[0:04:14.80 --> 0:04:21.20]	  know about the car. So all these characteristics, then highway, MPG, I think it's highway miles
[0:04:21.20 --> 0:04:28.70]	  per gallon, like how many miles it can drive per gallon of petroleum, like a few,
[0:04:29.14 --> 0:04:36.04]	  then city, like how many miles it can drive in a city per gallon. And popularity, this is something
[0:04:36.04 --> 0:0]	  the authors of this data set did is they took a look at Twitter and instructed how many mentions
[0:04:46.06 --> 0:0]	  car had. So basically the idea here is a more popular car has more mentions.
[0:04:52.58 --> 0:04:57.58]	  And then finally, this MSRP, this is what we want to predict. So these are the prices of cars.
[0:04:57.96 --> 0:05:04.88]	  So of course, there are many, many different values here. Okay, so this is the data we have.
[0:05:05.62 --> 0:05:13.06]	  And now what we'll do next is we will look at this price.
[0:0 --> 0:05:22.24]	  This price column closer. So for that, we will use, we will visualize it. We want to look at
[0:05:22.24 --> 0:05:28.06]	  graphically because looking at these numbers is not very informative. So we don't see the big picture.
[0:0 --> 0:05:35.58]	  So for this, for plotting, we will use two libraries. So one is called mudplotlib,
[0:05:35.82 --> 0:05:41.98]	  mudplotlib, and the other one is seaborn. So mudplotlib is more like low level one and seaborn
[0:05:41.98 --> 0:05:48.90]	  is a library on top of it that makes things easier. So we'll just see in a moment how to use this.
[0:05:49.68 --> 0:05:56.76]	  And this line here is needed to make sure that all these plots can be displayed in a notebook.
[0:05:57.24 --> 0:06:03.52]	  So we need to have this. So what we want to look now is at the distribution of prices
[0:06:03.52 --> 0:06:09.38]	  to see how many different prices are there. And so I'll just,
[0:06:10.64 --> 0:06:15.44]	  if you know what histogram is, this is what we want to do. If you don't, you'll see now.
[0:06:16.32 --> 0:06:25.80]	  So we want to plot the histogram of MSRP and it will just show us the shape of data.
[0:06:26.26 --> 0:06:34.72]	  So this is not very easy to see. Let's use a smaller amount of bins. So bins is basically,
[0:06:35.84 --> 0:06:45.14]	  so now let me execute. So you see here this bar. So bins is how many bars we actually have. So here
[0:06:45.14 --> 0:06:58.46]	  we would have 40 bars, 50 bars, sorry. So we can also, so let's have 10. So the bars will be
[0:06:58.54 --> 0:07:09.38]	  a lot bigger. So let's use 50. And what we see here is, so this is the distribution of data and
[0:07:09.38 --> 0:07:17.92]	  this notation here. So this actually is one million. So this is scientific notation.
[0:07:19.58 --> 0:07:28.30]	  One E6 means 10 to six. And yeah, so this is basically one million. So what we see is there
[0:07:28.30 --> 0:07:36.96]	  there are a lot of prices that are pretty cheap. So like most of the cars are here.
[0:07:37.76 --> 0:07:43.88]	  And then there are very few cars that are super expensive. So maybe there is just one car that
[0:07:43.88 --> 0:07:49.44]	  costs one million. Maybe there is one car that, it's two millions. So there is maybe one car that
[0:07:49.44 --> 0:07:55.48]	  costs two million. There is maybe one car that costs 1.5 millions. Maybe there are a few cars that
[0:07:55.48 --> 0:08:03.06]	  cost one million. So there are not so many of them. And the majority, like most of the data,
[0:08:03.06 --> 0:08:08.94]	  is concentrated here. And this effect is called, like this kind of distribution is called long
[0:08:10.34 --> 0:0]	  tail distribution because you can think of this as a tail.
[0:08:14.44 --> 0:08:21.18]	  So this is like there are very shallow. So there are not so many values, but
[0:08:21.18 --> 0:08:28.66]	  they have huge values, but most of the data is located here. So this is a long tail distribution.
[0:08:29.52 --> 0:08:36.28]	  So we need to zoom out, to zoom in a bit. So for that, what we can do is we can just,
[0:08:36.52 --> 0:08:48.02]	  let's say, look at prices that are not so large, let's say 100,000. So here it's a bit clearer.
[0:08:48.40 --> 0:08:57.62]	  So now we can actually see and think what we are looking at here is this part. So only a little
[0:08:57.62 --> 0:09:05.72]	  bit here. So we don't look at this at all at this tail. So we look only at this here, we just zoomed
[0:09:06.28 --> 0:09:16.76]	  in on that. So this is how it looks like. So this one is, like it's easier to actually see
[0:09:16.76 --> 0:09:26.90]	  visually. So most of the cars, they are, so yeah, so this is like maybe the average price
[0:09:26.96 --> 0:09:40.18]	  somewhere here. So this, we see that this is actually 1000. So we have this strange peak
[0:09:40.18 --> 0:09:47.42]	  of cars that cost 1000. Probably this is the minimal price that is possible to put on this
[0:09:47.42 --> 0:09:54.66]	  platform. That's why we have a bunch of cars that cost 1000. And then, yeah, so it slowly goes to,
[0:09:55.86 --> 0:10:08.66]	  I don't know, it's 25,000, I think. And then we have a lot of cars, around 700 cars that cost around
[0:10:08.66 --> 0:10:17.92]	  25,000. And then the number of cars with this price goes down. I think it's pretty reasonable
[0:10:17.92 --> 0:10:24.62]	  to expect this kind of distribution. So the only strange thing is here, this 1000.
[0:10:26.54 --> 0:1]	  But so while it's not unexpected to see distribution like this, especially in prices,
[0:10:33.30 --> 0:10:39.44]	  and this long tail distributions are very common for prices, because there are, most of the things
[0:10:39.44 --> 0:10:46.90]	  are cheap, like for general public, let's say, but there are a few super expensive ones. There are
[0:10:46.90 --> 0:10:51.68]	  not so many people who can afford buying expensive ones. That's why there are not so many, but there
[0:10:51.68 --> 0:10:58.40]	  are some people who can actually afford. So for those, there is this very few ones that are
[0:10:58.40 --> 0:11:04.94]	  expensive, but for the rest of the population, we have cheaper cars. This kind of distribution is
[0:11:04.94 --> 0:11:13.84]	  not really good for machine learning. So this tail will confuse our model, right, to really screw
[0:11:14.86 --> 0:11:23.16]	  things. So what we want to do is we want to get rid of this long tail. And for that, what we usually
[0:11:23.16 --> 0:11:30.30]	  do is we apply the logarithmic distribution. So we apply the logarithm to the price, and we get,
[0:11:30.40 --> 0:11:39.68]	  let's say, more compact values. And the logarithm, so let me just show you. So
[0:11:40.98 --> 0:11:49.86]	  it's for large values, the value of the logarithm is not that large. So you see, here we go, like,
[0:11:49.90 --> 0:11:57.94]	  from 10 to 1000, but the increase between the logarithm of them is not that high. So it kind
[0:11:57.94 --> 0:12:06.26]	  of brings very high values and makes them lower. So this is one we want to use. The problem with
[0:12:06.26 --> 0:1]	  just logarithm is if we have a zero here, then it complains, right? So there is a logarithm of zero
[0:1 --> 0:12:23.88]	  doesn't exist. Even though it's not the case for our particular case, in our case, we have prices
[0:12:23.88 --> 0:12:36.02]	  that are always 1000 or more. It's pretty common to add one to all the, so we just add one everywhere.
[0:12:36.88 --> 0:12:43.74]	  And this way, we make sure that we don't have this situation. So the logarithm of one is zero,
[0:12:44.42 --> 0:12:51.12]	  and the logarithm of zero doesn't exist. So we just add one everywhere. And that's why we make sure
[0:12:51.12 --> 0:13:02.14]	  that things are always positive. So we don't have these situations when we get problems.
[0:13:03.20 --> 0:13:10.86]	  And then we don't want to add this plus one every time manually. So there is actually a function in
[0:13:10.86 --> 0:13:22.66]	  NumPy that can help us. It's a shortcut. So it's called log1p. So it does one p stands for plus one.
[0:13:23.48 --> 0:13:28.68]	  So it adds one to all the values, and then it takes the logarithm. So this is actually
[0:13:29.06 --> 0:13:37.14]	  the same as we did previously. Just for a few values, type it.
[0:13:40.20 --> 0:13:47.96]	  So we see that, okay, so we see that the values here that we have, they are exactly the same.
[0:13:48.72 --> 0:13:56.76]	  So NumPy just does this plus one for us. So we want to use this for our prices.
[0:13:57.66 --> 0:14:08.30]	  So let's see, let's call it log, press locks, and we'll use this log1p function.
[0:14:09.82 --> 0:14:21.38]	  So here, yes, so now if we look at this series now, so it looks different now. So all these
[0:14:21.52 --> 0:14:27.92]	  values became smaller. We can draw it now. We can plot a histogram. Let's do this.
[0:14:30.60 --> 0:14:41.74]	  This is how it looks like now. So the tail is gone. So you see that, yeah, so there is no tail.
[0:14:42.26 --> 0:14:48.64]	  Like all these, all these large prices, they kind of collapse into this area,
[0:14:49.06 --> 0:14:55.70]	  right, and all the prices, like all the cars for usual consumers, they're still concentrated
[0:14:55.70 --> 0:15:07.88]	  around here. And this shape now resembles a bit, this bell curve shape. This is called normal distribution.
[0:15:09.80 --> 0:15:11.28]	  Normal distribution.
[0:15:16.70 --> 0:15:22.44]	  And having a distribution that looks like normal, even though, yeah, we have here this weird peak,
[0:15:23.02 --> 0:15:30.10]	  but anyways, so this looks more like normal. So we have like a clear center of the distribution.
[0:15:30.54 --> 0:15:36.12]	  And then it, when it goes to the left or to the right, it kind of goes down, right.
[0:15:36.28 --> 0:1]	  So this situation is ideal for models. So models, if your target variable looks like that,
[0:15:43.22 --> 0:15:50.90]	  models do quite well when they need to predict this. I mean, they do a lot better than
[0:15:50.90 --> 0:15:56.04]	  with long tail distributions. And long tail distributions usually confuse models. So we
[0:15:56.04 --> 0:16:03.64]	  typically want to get rid of long tail distributions. And one way of doing this is exactly what we just
[0:16:04.70 --> 0:16:14.04]	  saw is applying the logarithm of the price. Okay, so what we also want to do before we finish
[0:16:14.04 --> 0:16:24.26]	  this lesson is look at the missing values. So we have some data and some of these values might be
[0:16:24.26 --> 0:16:32.04]	  missing. I don't know if we saw here, like when we were looking, yeah, so let's say number of doors,
[0:16:32.06 --> 0:16:38.80]	  you see that there is this none. So none means not a number or in pandas, it usually
[0:16:38.80 --> 0:16:46.50]	  means that this value doesn't, it's missing. So it wasn't recorded. So let's see how many
[0:16:46.50 --> 0:16:55.72]	  of them are there. So for that, there is a function called isNull in pandas. So this,
[0:16:55.98 --> 0:17:03.64]	  for every cell it says if this, the value in this cell is null or not, is missing or not,
[0:17:04.16 --> 0:17:10.42]	  it's not super useful in this form. That's why we do some. So it sums across columns.
[0:17:10.88 --> 0:17:18.26]	  And then for each column, it tells us how many missing values. And we see that there are
[0:17:18.26 --> 0:17:22.96]	  quite a few missing values. So for some cars, we don't know what's the
[0:17:23.32 --> 0:17:30.10]	  fuel type, what's the market category, how many horsepower are there, how many cylinders
[0:17:30.10 --> 0:17:34.72]	  are there. So this is something we'll need to keep in mind when we actually
[0:17:34.72 --> 0:17:46.72]	  do, when we train our model. Okay. And that's it. So we look at the different values. So we
[0:17:47.10 --> 0:17:52.58]	  try to make sense from the data. So we need to take a look at this.
[0:17:53.20 --> 0:17:59.82]	  Then next we looked at the distribution of the price and concluded that it has long tail. That's
[0:17:59.82 --> 0:18:07.22]	  why we removed the effect of long tail with logarithm transformation. And then we finally,
[0:18:07.48 --> 0:18:13.48]	  at the end, we looked at the missing values and we saw that, yeah, there are missing values. And
[0:18:13.48 --> 0:1]	  we know that before training a model, we'll need to do something with them. Okay. And in the next
[0:1 --> 0:18:28.16]	  lesson, we will talk about setting up the validation framework. Before we train a model,
[0:18:28.28 --> 0:18:33.84]	  we need to make sure that we can validate the model. And we will set up this framework in the next
[0:18:33.84 --> 0:18:34.10]	  lesson.
