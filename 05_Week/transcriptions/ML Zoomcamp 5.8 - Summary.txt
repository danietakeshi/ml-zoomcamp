[0:00:00.12 --> 0:00:02.60]	  Hello everyone. This is lesson eight of machine learning
[0:00:02.60 --> 0:00:06.76]	  zoom comp session five. And in this lesson, we will just go
[0:00:06.76 --> 0:00:10.74]	  over what we studied, what we learned in this week. What we
[0:00:10.74 --> 0:00:14.72]	  did is we took a model that we trained in the previous two
[0:00:14.72 --> 0:00:18.46]	  weeks. So it was the term prediction model. And we saw
[0:00:18.46 --> 0:00:21.42]	  how we can save this model from a Jupyter notebook first
[0:00:21.42 --> 0:00:23.90]	  actually turn this Jupyter notebook in a script. I think
[0:00:23.90 --> 0:00:26.42]	  it's always a good idea to do that. And then we save the
[0:00:26.42 --> 0:00:30.12]	  pickle file. And then we saw how we can actually put this
[0:00:30.12 --> 0:00:33.60]	  pickle file in a flash service. And then with a web service,
[0:00:33.60 --> 0:00:38.18]	  we can expose the model to other services. Other services can
[0:00:38.18 --> 0:00:42.66]	  use this. And actually, this makes this week very important.
[0:00:42.86 --> 0:00:47.16]	  Because if we cannot do this, then no matter how good our
[0:00:47.16 --> 0:0]	  model is, if other services cannot use it, then our model is
[0:0 --> 0:00:55.38]	  useless. So this is for quite important week, actually, and we
[0:00:55.38 --> 0:00:58.54]	  learned a lot. So we learned how to wrap our model, how to put
[0:00:58.54 --> 0:0]	  our model inside a web service. Then we also talked about
[0:0 --> 0:01:05.58]	  manage independence is so how we do it in such a way that our
[0:01:05.58 --> 0:01:09.38]	  service does not conflict with other services. So we talked
[0:01:09.38 --> 0:01:13.24]	  about virtual environments. And we also talked about Docker. And
[0:01:13.24 --> 0:01:16.50]	  it's also a good idea to put things in Docker, because this
[0:01:16.50 --> 0:01:19.22]	  way you're running complete isolation from other services.
[0:01:19.22 --> 0:01:21.92]	  And when you have a Docker container, you can just take it
[0:01:21.92 --> 0:01:26.42]	  as is and deploy it to some cloud service. And I think most of
[0:01:26.42 --> 0:01:29.72]	  the cloud providers support deploying a container. And we
[0:01:29.72 --> 0:01:32.74]	  saw how to do this with elastic beanstalk. But this is not the
[0:01:32.74 --> 0:01:35.60]	  only option. There are many, many other options where you can
[0:01:35.60 --> 0:01:39.04]	  take a Docker container that we built here and just deploy it
[0:01:39.04 --> 0:01:42.40]	  as is. And of course, you can check it yourself, see what are
[0:01:42.40 --> 0:01:46.06]	  the other services are there. So I think that's it for this week.
[0:01:46.22 --> 0:01:49.08]	  I hope you enjoyed it. And see you next week.
